{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QdO4x-j2pEx",
        "colab_type": "text"
      },
      "source": [
        "**Downgrade Keras and import necessary libraries:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_cR7g2-OZz",
        "colab_type": "code",
        "outputId": "772e9014-1cae-432d-88d7-83cf41181e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip install keras==2.1.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.2.4:\n",
            "  Successfully uninstalled Keras-2.2.4\n",
            "Collecting keras==2.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.16.3)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7ZTEXMb-S5G",
        "colab_type": "code",
        "outputId": "8b915028-cbb0-4fe7-89e0-0c874a19f054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "#fr_utils imports\n",
        "\n",
        "from numpy import genfromtxt\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#inception_blocks_v2 imports\n",
        "\n",
        "from keras.layers.core import Lambda, Flatten, Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djJHrf0Q27Ah",
        "colab_type": "text"
      },
      "source": [
        "**Define classes and functions for face recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOtn-Ex-VZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################### fr_utils.py ############\n",
        "\n",
        "class Fr_Utils:\n",
        "    _FLOATX = 'float32'\n",
        "\n",
        "    def variable(self, value, dtype=_FLOATX, name=None):\n",
        "        v = tf.Variable(np.asarray(value, dtype=dtype), name=name)\n",
        "        _get_session().run(v.initializer)\n",
        "        return v\n",
        "\n",
        "    def shape(self, x):\n",
        "        return x.get_shape()\n",
        "\n",
        "    def square(self, x):\n",
        "        return tf.square(x)\n",
        "\n",
        "    def zeros(self, shape, dtype=_FLOATX, name=None):\n",
        "        return variable(np.zeros(shape), dtype, name)\n",
        "\n",
        "    def concatenate(self, tensors, axis=-1):\n",
        "        if axis < 0:\n",
        "            axis = axis % len(tensors[0].get_shape())\n",
        "        return tf.concat(axis, tensors)\n",
        "\n",
        "    def LRN2D(self, x):\n",
        "        return tf.nn.lrn(x, alpha=1e-4, beta=0.75)\n",
        "\n",
        "    def conv2d_bn(x,\n",
        "                  layer=None,\n",
        "                  cv1_out=None,\n",
        "                  cv1_filter=(1, 1),\n",
        "                  cv1_strides=(1, 1),\n",
        "                  cv2_out=None,\n",
        "                  cv2_filter=(3, 3),\n",
        "                  cv2_strides=(1, 1),\n",
        "                  padding=None):\n",
        "        num = '' if cv2_out == None else '1'\n",
        "        tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, data_format='channels_first', name=layer+'_conv'+num)(x)\n",
        "        tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
        "        tensor = Activation('relu')(tensor)\n",
        "        if padding == None:\n",
        "            return tensor\n",
        "        tensor = ZeroPadding2D(padding=padding, data_format='channels_first')(tensor)\n",
        "        if cv2_out == None:\n",
        "            return tensor\n",
        "        tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, data_format='channels_first', name=layer+'_conv'+'2')(tensor)\n",
        "        tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
        "        tensor = Activation('relu')(tensor)\n",
        "        return tensor\n",
        "\n",
        "    WEIGHTS = [\n",
        "      'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3',\n",
        "      'inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
        "      'inception_3a_pool_conv', 'inception_3a_pool_bn',\n",
        "      'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2',\n",
        "      'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2',\n",
        "      'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2',\n",
        "      'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2',\n",
        "      'inception_3b_pool_conv', 'inception_3b_pool_bn',\n",
        "      'inception_3b_1x1_conv', 'inception_3b_1x1_bn',\n",
        "      'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2',\n",
        "      'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2',\n",
        "      'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2',\n",
        "      'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2',\n",
        "      'inception_4a_pool_conv', 'inception_4a_pool_bn',\n",
        "      'inception_4a_1x1_conv', 'inception_4a_1x1_bn',\n",
        "      'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2',\n",
        "      'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2',\n",
        "      'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2',\n",
        "      'inception_5a_pool_conv', 'inception_5a_pool_bn',\n",
        "      'inception_5a_1x1_conv', 'inception_5a_1x1_bn',\n",
        "      'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2',\n",
        "      'inception_5b_pool_conv', 'inception_5b_pool_bn',\n",
        "      'inception_5b_1x1_conv', 'inception_5b_1x1_bn',\n",
        "      'dense_layer'\n",
        "    ]\n",
        "\n",
        "    conv_shape = {\n",
        "      'conv1': [64, 3, 7, 7],\n",
        "      'conv2': [64, 64, 1, 1],\n",
        "      'conv3': [192, 64, 3, 3],\n",
        "      'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
        "      'inception_3a_pool_conv': [32, 192, 1, 1],\n",
        "      'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
        "      'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
        "      'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
        "      'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
        "      'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
        "      'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
        "      'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
        "      'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
        "      'inception_3b_pool_conv': [64, 256, 1, 1],\n",
        "      'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
        "      'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
        "      'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
        "      'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
        "      'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
        "      'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
        "      'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
        "      'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
        "      'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
        "      'inception_4a_pool_conv': [128, 640, 1, 1],\n",
        "      'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
        "      'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
        "      'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
        "      'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
        "      'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
        "      'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
        "      'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
        "      'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
        "      'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
        "      'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
        "      'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
        "      'inception_5b_pool_conv': [96, 736, 1, 1],\n",
        "      'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
        "    }\n",
        "\n",
        "    global load_weights_from_FaceNet\n",
        "    def load_weights_from_FaceNet(FRmodel):\n",
        "        # Load weights from csv files (which was exported from Openface torch model)\n",
        "        weights = Fr_Utils.WEIGHTS\n",
        "        weights_dict = Fr_Utils.load_weights()\n",
        "\n",
        "        # Set layer weights of the model\n",
        "        for name in weights:\n",
        "            if FRmodel.get_layer(name) != None:\n",
        "                FRmodel.get_layer(name).set_weights(weights_dict[name])\n",
        "            elif model.get_layer(name) != None:\n",
        "                model.get_layer(name).set_weights(weights_dict[name])\n",
        "\n",
        "    def load_weights():\n",
        "        # Set weights path\n",
        "        dirPath = './weights'\n",
        "        fileNames = filter(lambda f: not f.startswith('.'), os.listdir(dirPath))\n",
        "        paths = {}\n",
        "        weights_dict = {}\n",
        "\n",
        "        for n in fileNames:\n",
        "            paths[n.replace('.csv', '')] = dirPath + '/' + n\n",
        "\n",
        "        for name in Fr_Utils.WEIGHTS:\n",
        "            if 'conv' in name:\n",
        "                conv_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "                conv_w = np.reshape(conv_w, Fr_Utils.conv_shape[name])\n",
        "                conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
        "                conv_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "                weights_dict[name] = [conv_w, conv_b]     \n",
        "            elif 'bn' in name:\n",
        "                bn_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "                bn_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "                bn_m = genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
        "                bn_v = genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
        "                weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
        "            elif 'dense' in name:\n",
        "                dense_w = genfromtxt(dirPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
        "                dense_w = np.reshape(dense_w, (128, 736))\n",
        "                dense_w = np.transpose(dense_w, (1, 0))\n",
        "                dense_b = genfromtxt(dirPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
        "                weights_dict[name] = [dense_w, dense_b]\n",
        "\n",
        "        return weights_dict\n",
        "      \n",
        "    def select_main_face(faces):\n",
        "        main_face = []\n",
        "        square = 0\n",
        "        for face in faces:\n",
        "          face_sq = face[2]*face[3]\n",
        "          if (face_sq > square):\n",
        "            square = face_sq\n",
        "            main_face = face\n",
        "\n",
        "        return main_face\n",
        "\n",
        "    global img_path_to_encoding\n",
        "    def img_path_to_encoding(image_path, model, padding = 0.25):\n",
        "        face = detect_face(image_path, padding)\n",
        "        return img_to_encoding(face, model)\n",
        "\n",
        "    global img_to_encoding\n",
        "    def img_to_encoding(image, model):\n",
        "        image = cv2.resize(image, (96, 96)) \n",
        "        img = image[...,::-1]\n",
        "        img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
        "        x_train = np.array([img])\n",
        "        embedding = model.predict_on_batch(x_train)\n",
        "        return embedding\n",
        "\n",
        "    global detect_face\n",
        "    def detect_face(image_path, padding = 0.25):\n",
        "        if not os.path.isfile(image_path):\n",
        "            raise Exception('No such file in directory: ' + image_path)\n",
        "        img = cv2.imread(image_path,1)\n",
        "        facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "        faces = facecascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
        "        face = Fr_Utils.select_main_face(faces)\n",
        "        if (len(face)<4):\n",
        "            raise Exception('No faces detected: ' + image_path)\n",
        "        x,y,w,h = face[0], face[1], face[2], face[3]        \n",
        "        if (0 < padding < 1):\n",
        "            padding = int(padding*(w+h)/2)\n",
        "        x,y,w,h = x - padding, y - padding, w + 2*padding, h + 2*padding \n",
        "        face_detect = img[max(0,y):min(img.shape[0],y+h),max(0,x):min(img.shape[1], x+w)]\n",
        "        return face_detect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1YlzL1v1JUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################## inception_blocks_v2.py ######################\n",
        "\n",
        "class Inception_Blocks:\n",
        "    \n",
        "    global inception_block_1a\n",
        "    def inception_block_1a(X):\n",
        "        \"\"\"\n",
        "        Implementation of an inception block\n",
        "        \"\"\"\n",
        "\n",
        "        X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name ='inception_3a_3x3_conv1')(X)\n",
        "        X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name = 'inception_3a_3x3_bn1')(X_3x3)\n",
        "        X_3x3 = Activation('relu')(X_3x3)\n",
        "        X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "        X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3a_3x3_conv2')(X_3x3)\n",
        "        X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn2')(X_3x3)\n",
        "        X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "        X_5x5 = Conv2D(16, (1, 1), data_format='channels_first', name='inception_3a_5x5_conv1')(X)\n",
        "        X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn1')(X_5x5)\n",
        "        X_5x5 = Activation('relu')(X_5x5)\n",
        "        X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "        X_5x5 = Conv2D(32, (5, 5), data_format='channels_first', name='inception_3a_5x5_conv2')(X_5x5)\n",
        "        X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn2')(X_5x5)\n",
        "        X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "        X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "        X_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(X_pool)\n",
        "        X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(X_pool)\n",
        "        X_pool = Activation('relu')(X_pool)\n",
        "        X_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(X_pool)\n",
        "\n",
        "        X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3a_1x1_conv')(X)\n",
        "        X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_1x1_bn')(X_1x1)\n",
        "        X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "        # CONCAT\n",
        "        inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global inception_block_1b\n",
        "    def inception_block_1b(X):\n",
        "        X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3b_3x3_conv1')(X)\n",
        "        X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn1')(X_3x3)\n",
        "        X_3x3 = Activation('relu')(X_3x3)\n",
        "        X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "        X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3b_3x3_conv2')(X_3x3)\n",
        "        X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn2')(X_3x3)\n",
        "        X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "        X_5x5 = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3b_5x5_conv1')(X)\n",
        "        X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn1')(X_5x5)\n",
        "        X_5x5 = Activation('relu')(X_5x5)\n",
        "        X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "        X_5x5 = Conv2D(64, (5, 5), data_format='channels_first', name='inception_3b_5x5_conv2')(X_5x5)\n",
        "        X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn2')(X_5x5)\n",
        "        X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "        X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "        X_pool = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_pool_conv')(X_pool)\n",
        "        X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_pool_bn')(X_pool)\n",
        "        X_pool = Activation('relu')(X_pool)\n",
        "        X_pool = ZeroPadding2D(padding=(4, 4), data_format='channels_first')(X_pool)\n",
        "\n",
        "        X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_1x1_conv')(X)\n",
        "        X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(X_1x1)\n",
        "        X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "        inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global inception_block_1c\n",
        "    def inception_block_1c(X):\n",
        "        X_3x3 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_3c_3x3',\n",
        "                               cv1_out=128,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=256,\n",
        "                               cv2_filter=(3, 3),\n",
        "                               cv2_strides=(2, 2),\n",
        "                               padding=(1, 1))\n",
        "\n",
        "        X_5x5 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_3c_5x5',\n",
        "                               cv1_out=32,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=64,\n",
        "                               cv2_filter=(5, 5),\n",
        "                               cv2_strides=(2, 2),\n",
        "                               padding=(2, 2))\n",
        "\n",
        "        X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "        X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "        inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global inception_block_2a\n",
        "    def inception_block_2a(X):\n",
        "        X_3x3 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_4a_3x3',\n",
        "                               cv1_out=96,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=192,\n",
        "                               cv2_filter=(3, 3),\n",
        "                               cv2_strides=(1, 1),\n",
        "                               padding=(1, 1))\n",
        "        X_5x5 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_4a_5x5',\n",
        "                               cv1_out=32,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=64,\n",
        "                               cv2_filter=(5, 5),\n",
        "                               cv2_strides=(1, 1),\n",
        "                               padding=(2, 2))\n",
        "\n",
        "        X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "        X_pool = Fr_Utils.conv2d_bn(X_pool,\n",
        "                               layer='inception_4a_pool',\n",
        "                               cv1_out=128,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               padding=(2, 2))\n",
        "        X_1x1 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_4a_1x1',\n",
        "                               cv1_out=256,\n",
        "                               cv1_filter=(1, 1))\n",
        "        inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global inception_block_2b\n",
        "    def inception_block_2b(X):\n",
        "        #inception4e\n",
        "        X_3x3 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_4e_3x3',\n",
        "                               cv1_out=160,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=256,\n",
        "                               cv2_filter=(3, 3),\n",
        "                               cv2_strides=(2, 2),\n",
        "                               padding=(1, 1))\n",
        "        X_5x5 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_4e_5x5',\n",
        "                               cv1_out=64,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=128,\n",
        "                               cv2_filter=(5, 5),\n",
        "                               cv2_strides=(2, 2),\n",
        "                               padding=(2, 2))\n",
        "\n",
        "        X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "        X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "        inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "        return inception\n",
        "      \n",
        "    global inception_block_3a\n",
        "    def inception_block_3a(X):\n",
        "        X_3x3 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_5a_3x3',\n",
        "                               cv1_out=96,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=384,\n",
        "                               cv2_filter=(3, 3),\n",
        "                               cv2_strides=(1, 1),\n",
        "                               padding=(1, 1))\n",
        "        X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "        X_pool = Fr_Utils.conv2d_bn(X_pool,\n",
        "                               layer='inception_5a_pool',\n",
        "                               cv1_out=96,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               padding=(1, 1))\n",
        "        X_1x1 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_5a_1x1',\n",
        "                               cv1_out=256,\n",
        "                               cv1_filter=(1, 1))\n",
        "\n",
        "        inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global inception_block_3b\n",
        "    def inception_block_3b(X):\n",
        "        X_3x3 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_5b_3x3',\n",
        "                               cv1_out=96,\n",
        "                               cv1_filter=(1, 1),\n",
        "                               cv2_out=384,\n",
        "                               cv2_filter=(3, 3),\n",
        "                               cv2_strides=(1, 1),\n",
        "                               padding=(1, 1))\n",
        "        X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "        X_pool = Fr_Utils.conv2d_bn(X_pool,\n",
        "                               layer='inception_5b_pool',\n",
        "                               cv1_out=96,\n",
        "                               cv1_filter=(1, 1))\n",
        "        X_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_pool)\n",
        "\n",
        "        X_1x1 = Fr_Utils.conv2d_bn(X,\n",
        "                               layer='inception_5b_1x1',\n",
        "                               cv1_out=256,\n",
        "                               cv1_filter=(1, 1))\n",
        "        inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "        return inception\n",
        "\n",
        "    global faceRecoModel\n",
        "    def faceRecoModel(input_shape):\n",
        "        \"\"\"\n",
        "        Implementation of the Inception model used for FaceNet\n",
        "\n",
        "        Arguments:\n",
        "        input_shape -- shape of the images of the dataset\n",
        "        Returns:\n",
        "        model -- a Model() instance in Keras\n",
        "        \"\"\"\n",
        "\n",
        "        # Define the input as a tensor with shape input_shape\n",
        "        X_input = Input(input_shape)\n",
        "\n",
        "        # Zero-Padding\n",
        "        X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "        # First Block\n",
        "        X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
        "        X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
        "        X = Activation('relu')(X)\n",
        "\n",
        "        # Zero-Padding + MAXPOOL\n",
        "        X = ZeroPadding2D((1, 1))(X)\n",
        "        X = MaxPooling2D((3, 3), strides = 2)(X)\n",
        "\n",
        "        # Second Block\n",
        "        X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2')(X)\n",
        "        X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
        "        X = Activation('relu')(X)\n",
        "\n",
        "        # Zero-Padding + MAXPOOL\n",
        "        X = ZeroPadding2D((1, 1))(X)\n",
        "\n",
        "        # Second Block\n",
        "        X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
        "        X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
        "        X = Activation('relu')(X)\n",
        "\n",
        "        # Zero-Padding + MAXPOOL\n",
        "        X = ZeroPadding2D((1, 1))(X)\n",
        "        X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n",
        "\n",
        "        # Inception 1: a/b/c\n",
        "        X = inception_block_1a(X)\n",
        "        X = inception_block_1b(X)\n",
        "        X = inception_block_1c(X)\n",
        "\n",
        "        # Inception 2: a/b\n",
        "        X = inception_block_2a(X)\n",
        "        X = inception_block_2b(X)\n",
        "\n",
        "        # Inception 3: a/b\n",
        "        X = inception_block_3a(X)\n",
        "        X = inception_block_3b(X)\n",
        "\n",
        "        # Top layer\n",
        "        X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
        "        X = Flatten()(X)\n",
        "        X = Dense(128, name='dense_layer')(X)\n",
        "\n",
        "        # L2 normalization\n",
        "        X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "\n",
        "        # Create model instance\n",
        "        model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWnHYjb-QB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_database(padding = 0.25):\n",
        "  database = {}\n",
        "\n",
        "  # load all the images of individuals to recognize into the database\n",
        "  for file in glob.glob(\"images/*\"):\n",
        "    identity = os.path.splitext(os.path.basename(file))[0]\n",
        "    database[identity] = img_path_to_encoding(file, FRmodel, padding)\n",
        "\n",
        "  return database"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wreDLxoZApLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def who_is_it(image, database, model, padding = 0.25):\n",
        "    face = detect_face(image, padding)\n",
        "    encoding = img_to_encoding(face, model)\n",
        "    \n",
        "    min_dist = 100\n",
        "    identity = None\n",
        "\n",
        "    for (name, db_enc) in database.items():\n",
        "        dist = np.linalg.norm(db_enc - encoding)\n",
        "        print('distance %s - %s is %s' %(image, name, dist))\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    if min_dist > 0.52:\n",
        "        return None\n",
        "    else:\n",
        "        return identity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PrTucKitVDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.3):\n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,\n",
        "               positive)), axis=-1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, \n",
        "               negative)), axis=-1)\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTFpTLJx2kIc",
        "colab_type": "text"
      },
      "source": [
        "**Load images and weights** \n",
        " > To load images, weights.zip and xml for opencv - click upload on Files tab \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyDbNBbU3oU4",
        "colab_type": "code",
        "outputId": "a9574090-005a-4ca7-a852-501ef2ba46ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "!unzip weights.zip\n",
        "!unzip images.zip\n",
        "!unzip test.zip"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  images.zip\n",
            "   creating: images/\n",
            "  inflating: images/levin.jpg        \n",
            "  inflating: images/mark.jpg         \n",
            "  inflating: images/putin.jpg        \n",
            "  inflating: images/radcliffe.jpg    \n",
            "  inflating: images/smith.jpg        \n",
            "Archive:  test.zip\n",
            "   creating: newtest/\n",
            "  inflating: newtest/dark.jpg        \n",
            " extracting: newtest/glasses.jpg     \n",
            "  inflating: newtest/light.jpg       \n",
            "  inflating: newtest/lowres.jpg      \n",
            " extracting: newtest/profile.jpg     \n",
            "  inflating: newtest/shirt.jpg       \n",
            " extracting: newtest/slight_turn.jpg  \n",
            " extracting: newtest/smile.jpg       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KCUepV5fGN",
        "colab_type": "text"
      },
      "source": [
        "**Test launch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIlTSuI5iDE",
        "colab_type": "code",
        "outputId": "0ddf5a66-b60c-49d3-ee8b-7d43e1b04e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "## Build a model from weights\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
        "\n",
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EynWuAALtHWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save pictures from 'images' folder to database\n",
        "\n",
        "database = prepare_database(0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx1NKZdetlWK",
        "colab_type": "code",
        "outputId": "d6ea2633-bc23-43aa-9036-6d44a4dbeb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "source": [
        "## Upload a picture to current folder (/content) and proceed the recognition\n",
        "for img in os.listdir('test'):\n",
        "    res = who_is_it('test/'+ img, database, FRmodel, 0.33)\n",
        "    if (res != None):\n",
        "        print('Current user is ' + res + '\\n\\n')\n",
        "    else:\n",
        "        print('Undefined user \\n\\n')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distance test/dark.jpg - levin is 0.91488767\n",
            "distance test/dark.jpg - radcliffe is 1.1466024\n",
            "distance test/dark.jpg - putin is 0.9967839\n",
            "distance test/dark.jpg - smith is 0.9785047\n",
            "distance test/dark.jpg - mark is 0.68584967\n",
            "Undefined user \n",
            "\n",
            "\n",
            "distance test/slight_turn.jpg - levin is 0.502187\n",
            "distance test/slight_turn.jpg - radcliffe is 0.6823667\n",
            "distance test/slight_turn.jpg - putin is 0.78248864\n",
            "distance test/slight_turn.jpg - smith is 0.6205392\n",
            "distance test/slight_turn.jpg - mark is 0.9161137\n",
            "Current user is levin\n",
            "\n",
            "\n",
            "distance test/glasses.jpg - levin is 0.4417769\n",
            "distance test/glasses.jpg - radcliffe is 0.92514145\n",
            "distance test/glasses.jpg - putin is 0.9269645\n",
            "distance test/glasses.jpg - smith is 0.7628174\n",
            "distance test/glasses.jpg - mark is 0.8190089\n",
            "Current user is levin\n",
            "\n",
            "\n",
            "distance test/light.jpg - levin is 0.4877757\n",
            "distance test/light.jpg - radcliffe is 0.52891344\n",
            "distance test/light.jpg - putin is 0.83417577\n",
            "distance test/light.jpg - smith is 0.7013814\n",
            "distance test/light.jpg - mark is 0.94189525\n",
            "Current user is levin\n",
            "\n",
            "\n",
            "distance test/smile.jpg - levin is 0.34667626\n",
            "distance test/smile.jpg - radcliffe is 0.6320207\n",
            "distance test/smile.jpg - putin is 0.75876623\n",
            "distance test/smile.jpg - smith is 0.5735045\n",
            "distance test/smile.jpg - mark is 1.0407808\n",
            "Current user is levin\n",
            "\n",
            "\n",
            "distance test/lowres.jpg - levin is 0.49507886\n",
            "distance test/lowres.jpg - radcliffe is 0.5931313\n",
            "distance test/lowres.jpg - putin is 0.6351142\n",
            "distance test/lowres.jpg - smith is 0.39448035\n",
            "distance test/lowres.jpg - mark is 1.0805153\n",
            "Current user is smith\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}